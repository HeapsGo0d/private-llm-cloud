{
  "template_name": "Private LLM Cloud - Maximum Privacy",
  "template_description": "Production-ready private LLM inference with maximum privacy and security. Supports any HuggingFace model with intelligent GPU sizing and cost optimization.",
  "image": "ghcr.io/private-llm-cloud/private-llm:latest",
  "args": [],
  "jupyter": false,
  "jupyter_dir": "/app",
  "python_utf8": false,
  "lang_utf8": false,
  "disk_gb": 50,
  "ports": {
    "3000/tcp": 3000,
    "11434/tcp": 11434,
    "8000/tcp": 8000
  },
  "env": {
    "PRIVACY_MODE": "maximum",
    "DISABLE_TELEMETRY": "true",
    "ENCRYPT_STORAGE": "true",
    "API_KEY": "{{RANDOM_SECURE_KEY}}",
    "HF_TOKEN": "",
    "ALLOWED_IPS": "0.0.0.0/0",
    "DEFAULT_QUANTIZATION": "Q4_K_M",
    "AUTO_SHUTDOWN_IDLE_MINUTES": "60",
    "ENABLE_MONITORING": "true",
    "MAX_CONCURRENT_REQUESTS": "10",
    "LOG_LEVEL": "INFO",
    "VAST_AI_DEPLOYMENT": "true"
  },
  "runtype": "ssh interactive",
  "image_login": "root",
  "ssh_str": "",
  "jupyter_token": "",
  "direct_port_count": 3,
  "direct_port_start": 3000,
  "disk_space": 50,
  "inet_up_cost": 0.0,
  "inet_down_cost": 0.0,
  "min_download": 0,
  "min_upload": 0,
  "gpu_ram": 16,
  "gpu_name": "RTX 3090,RTX 4090,A100,H100",
  "cpu_ram": 16,
  "cpu_cores": 4,
  "cuda_max_vers": 12.1,
  "pci_gen": 3,
  "dlperf": 16,
  "flops_per_dphtotal": 128,
  "reliability": 0.9,
  "duration": 0,
  "onstart": "/app/scripts/startup.sh",
  "verification": "verified",
  "min_bid": 0.1,
  "max_bid": 2.0,
  "order": "dph+",
  "extra_filters": {},
  "docker_args": "",
  "onstart_cmd": "#!/bin/bash\nset -e\n\necho \"üîí Starting Private LLM Cloud on Vast.ai...\"\n\n# Wait for GPU detection\necho \"‚è≥ Waiting for GPU detection...\"\nuntil nvidia-smi > /dev/null 2>&1; do\n    echo \"Waiting for GPU...\"\n    sleep 5\ndone\n\necho \"‚úÖ GPU detected: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits)\"\n\n# Set permissions\nchmod +x /app/scripts/*.sh\n\n# Apply security hardening\necho \"üõ°Ô∏è Applying security hardening...\"\n/app/scripts/security-hardening.sh\n\n# Setup privacy controls\necho \"üîê Setting up privacy controls...\"\n/app/scripts/setup-privacy.sh\n\n# Start services\necho \"üöÄ Starting services...\"\n/app/scripts/startup.sh\n\necho \"‚úÖ Private LLM Cloud is ready!\"\necho \"üìä Web UI: https://$(curl -s ifconfig.me):3000\"\necho \"üîå API: https://$(curl -s ifconfig.me):11434\"\necho \"üõ°Ô∏è Privacy Dashboard: https://$(curl -s ifconfig.me):3000/privacy-dashboard.html\"\necho \"üîë API Key: ${API_KEY}\"\n\n# Create status file\necho '{\"status\": \"ready\", \"timestamp\": \"'$(date -Iseconds)'\"}' > /app/status.json\n\n# Keep container running\ntail -f /dev/null",
  "setup_commands": [
    "apt-get update -y",
    "apt-get install -y curl wget git htop",
    "pip install --upgrade pip",
    "echo 'Private LLM Cloud setup complete'"
  ],
  "readme": "# Private LLM Cloud - Vast.ai Template\n\n## üîí Maximum Privacy LLM Inference\n\nThis template provides a complete, production-ready system for running private LLM inference with maximum privacy and security on Vast.ai.\n\n### ‚ú® Key Features\n\n- **Complete Privacy Isolation**: No external data transmission after setup\n- **Encrypted Storage**: All conversations and models encrypted at rest\n- **Zero Telemetry**: No tracking, logging, or data collection\n- **OpenAI-Compatible API**: Works with iOS apps like Pal Chat\n- **Intelligent GPU Sizing**: Automatic VRAM calculation and optimization\n- **Cost Optimization**: Right-sized GPU recommendations\n- **Emergency Purge**: Secure data deletion capabilities\n\n### üöÄ Quick Start on Vast.ai\n\n1. **Search for Instances**:\n   - Minimum 16GB GPU RAM\n   - CUDA 11.8+ support\n   - Reliable provider (>90%)\n\n2. **Deploy Template**:\n   ```bash\n   # Use this template in Vast.ai marketplace\n   # Or deploy with custom settings\n   ```\n\n3. **Access Services**:\n   - Web UI: `https://your-instance-ip:3000`\n   - API: `https://your-instance-ip:11434`\n   - Privacy Dashboard: `https://your-instance-ip:3000/privacy-dashboard.html`\n\n### üîß Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `PRIVACY_MODE` | `maximum` | Privacy protection level |\n| `HF_TOKEN` | `` | HuggingFace token for downloads |\n| `API_KEY` | Auto-generated | Secure API access key |\n| `ALLOWED_IPS` | `0.0.0.0/0` | IP allowlist (set to your IP) |\n| `AUTO_SHUTDOWN_IDLE_MINUTES` | `60` | Auto-shutdown timer |\n\n### üõ°Ô∏è Security Best Practices\n\n1. **Set IP Allowlist**: Change `ALLOWED_IPS` to your IP address\n2. **Use Strong API Key**: The auto-generated key is secure\n3. **Monitor Privacy Dashboard**: Check for external connections\n4. **Enable Encryption**: All data encrypted by default\n\n### üì± iOS App Integration\n\n1. **Get Your Instance Details**:\n   ```bash\n   # Check logs for connection info\n   docker logs [container_id]\n   ```\n\n2. **Configure Your App**:\n   - API Endpoint: `https://your-instance-ip:11434`\n   - API Key: Check logs or Web UI\n   - Model: Download via Web UI first\n\n### üí∞ Cost Optimization\n\n- **Auto-shutdown**: Configured for 60 minutes idle\n- **GPU Recommendations**: Use VRAM calculator\n- **Model Quantization**: Q4_K_M for best balance\n- **Monitor Usage**: Built-in cost tracking\n\n### üîç Supported Models\n\n- **Size Range**: 7B to 120B+ parameters\n- **Formats**: GGUF, GPTQ, AWQ, safetensors\n- **Sources**: Any HuggingFace model\n- **Optimization**: Automatic quantization\n\n### üõ†Ô∏è Troubleshooting\n\n1. **Container not starting**:\n   ```bash\n   # Check logs\n   docker logs [container_id]\n   \n   # Verify GPU\n   nvidia-smi\n   ```\n\n2. **Cannot access Web UI**:\n   - Check firewall settings\n   - Verify port forwarding\n   - Confirm instance is running\n\n3. **Model download fails**:\n   - Add HuggingFace token\n   - Check internet connectivity\n   - Verify disk space\n\n### üîí Privacy Verification\n\n1. **Check Privacy Status**:\n   - Visit Privacy Dashboard\n   - Review security checklist\n   - Monitor network connections\n\n2. **Generate Privacy Report**:\n   ```bash\n   curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n        https://your-instance:8000/api/privacy/report\n   ```\n\n3. **Emergency Data Purge**:\n   - Use Web UI emergency button\n   - Or API endpoint: `/api/privacy/purge`\n\n---\n\n**‚ö†Ô∏è Important**: This system is designed for maximum privacy. Always verify your setup meets your security requirements before processing sensitive data.\n\n**üí° Tip**: For maximum security, set `ALLOWED_IPS` to your specific IP address and use a strong API key.",
  "tags": ["ai", "llm", "privacy", "security", "openai", "ollama", "inference", "private"],
  "category": "AI/ML",
  "subcategory": "Text Generation",
  "featured": true,
  "verified": true
}